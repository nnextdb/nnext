/*
 * Copyright NNext Co. and/or licensed to NNext Co.
 * @author [Peter. Njenga]
 *
 * This file and its contents are licensed under the NNext License.
 * Please see the included NOTICE for copyright information and
 * LICENSE for a copy of the license.
 */

// Standard Libraries
#include <algorithm>
#include <assert.h>
#include <iostream>
#include <memory>
#include <random>
#include <stdio.h>
#include <string>
#include <tuple>
#include <unordered_map>

// External Libraries
#include <argparse/argparse.hpp>
#include <faiss/IndexFlat.h>
#include <faiss/IndexHNSW.h>
#include <faiss/IndexNNDescent.h>
#include <faiss/MetricType.h>
#include <spdlog/fmt/fmt.h>
#include <google/protobuf/map.h>
#include <grpcpp/grpcpp.h>
#include <rocksdb/db.h>
#include <spdlog/spdlog.h>

// Internal Libraries
#include "protos/main.grpc.pb.h"
#include "server.h"
#include "util.h"

using nnext::NNext;
using namespace std;

#define INDEX_SIZE_THRESHOLD 5000
/*
 * TODO Move to utils.
 */

/*
***********************************************************************************************************************
*/

void NNextServiceImpl::_init() {
  /** Read the indices persisted to disk and return them.
   *
   * Use an open RocksDB connection to read from Disk serialized index
   * parameters.
   *
   * @param rocksdb: Connected RocksDB instance.
   */
  std::string value;
  rocksdb::Status db_status;

  if (p__index_list_pb == nullptr) {
    spdlog::warn("Null pointer passed; no existing DB index on file. Initializing a new IndexList.");
    p__index_list_pb = std::make_shared<nnext::IndexList>();
  }

  // Attempt read of previously recorded index list key from rocks DB.
  std::string sample_key = "sample_indexlist_key";
  db_status = _rocksdb->Get(rocksdb::ReadOptions(), sample_key, &value);

  if (!db_status.ok()) {
    spdlog::info("RocksDB tried to read from key '{}', but encountered error: {}", sample_key, db_status.ToString());
  } else {
    p__index_list_pb->ParseFromString(value);
    spdlog::info("Loaded {} indices from disk.",
                 p__index_list_pb->indices_size());
  }

  std::string vector_list_key;

  for (int i = 0; i < p__index_list_pb->indices_size(); i++) {
    const nnext::Index &pb__index = p__index_list_pb->indices(i);
    const int dims = pb__index.dims();
    const std::string index_name = pb__index.name();

    spdlog::debug("Reconstructing index [name={}, dims={} schema={}]",
                  index_name, dims, pb__index.schema().DebugString());

    /*
     * read index vectors from disk.
     */
    vector_list_key = fmt::format("index__{}__vectors]", index_name);

    spdlog::debug("Reading index vectors from RocksDB disk [key={}]",
                  vector_list_key);
    db_status = _rocksdb->Get(rocksdb::ReadOptions(), vector_list_key, &value);

    if (!db_status.ok())
      spdlog::error("RocksDB error {}", db_status.ToString());

    auto pb__vector_list = std::make_shared<nnext::VectorList>();
    pb__vector_list_map[index_name] = pb__vector_list;

    /*
     * Deserialize the vectors using gRPC protobufs.
     * Serialization/deserialization is a tricky operation that has lots of
     * edge-case depending on the system (OS, architecture, mood of the gods
     * e.t.c). Use gRPC to handle the nitty gritty.
     */
    pb__vector_list->ParseFromString(value);
    spdlog::debug("Loaded vectors from disk [index.name={} nvectors={}]",
                  index_name, pb__vector_list->rptd__vector_size());

    /*
     * Create a new index to store the elements.
     * TODO These numbers are hardcoded. You can surely do better than this.
     */
    const int n = pb__vector_list->rptd__vector_size();
    const size_t nlist = 4; // Number of cluster centroids.
    int m_pq = 128;
    int M = 16; // Number of neighbors used in the graph. A larger M is more
                // accurate but uses more memory
    std::vector<float> data_vec;

    /*
     * Create the approximated index and the storage (quantizer)
     */
    std::shared_ptr ptr__quantizer = std::make_shared<faiss::IndexFlat>(dims);
    std::shared_ptr curr_index = std::make_shared<faiss::IndexHNSW2Level>(
        ptr__quantizer.get(), nlist, m_pq, M);

    /*
     * Extract the vector data array
     */
    auto rptd__vector = pb__vector_list->mutable_rptd__vector();
    for (auto iter_rptd__vector = rptd__vector->begin();
         iter_rptd__vector < rptd__vector->end(); iter_rptd__vector++) {
      auto rptd__element = iter_rptd__vector->rptd__element();
      data_vec.insert(data_vec.end(), rptd__element.begin(),
                      rptd__element.end());
    }

    /*
     * Train the index 🎪🦭🐘🐅🤡 using 1/5th of the entire vector set
     * as the training set.
     */
    const unsigned int n_total = data_vec.size() / dims;
    const unsigned int n_train = n_total * 0.20;

    if (n_train > 300) {
      spdlog::info("Training [n_train={} index_name={}]", n_train, index_name);

      curr_index->train(n_train, &data_vec[0]);

      spdlog::info("Done training is_trained={} n_train={} index_name={}",
                   curr_index->is_trained, n_train, index_name);
    } else {
      spdlog::info("Skipped training. Not enough examples (<= 300)");
    }

    /*
     * Add the ANN index and quantizer into the map.
     */
    index_map.insert(std::make_pair(index_name, curr_index));
    storage_map.insert(std::make_pair(index_name, ptr__quantizer));

    /*
     * Add the elements to the index. Note we can directly access the underlying
     * float array pointer from the std::vector since vector elements are
     * guaranteed to be contiguous.
     */

    if (n_total > 5000) {
      spdlog::debug("Adding vectors to index [name={}]", index_name);
      curr_index->add(n, &data_vec[0]);

      spdlog::info("Added data to index [name={} ntotal={} is_trained={}]",
                   index_name, curr_index->ntotal, curr_index->is_trained);
    } else {
      spdlog::info("Adding data to flat index [name={}]", index_name);
      ptr__quantizer->add(n, &data_vec[0]);
    }
  }
}

grpc::Status NNextServiceImpl::GetIndex(grpc::ServerContext *p_context,
                                        const nnext::Index *p_request,
                                        nnext::Index *p_response) {
  std::string index_name = p_request->name();
  std::string log_msg;
  std::cout << "GetIndex: " << index_name << std::endl;

  /*
   * First check that the index is actually contained in the map.
   */
  if (!index_map.contains(index_name)) {
    log_msg = fmt::format("⚠️  Index does not exist [name={}]", index_name);
    spdlog::error(log_msg);
    return grpc::Status(grpc::StatusCode::NOT_FOUND, log_msg);
  }

  /*
   * Get the index and set the properties of the Index Proto
   */
  auto index = index_map[index_name];
  p_response->set_name(index_name);
  p_response->set_dims(index->d);
  p_response->set_ntotal(index->ntotal);
  p_response->set_is_trained(index->is_trained);

  /*
   * Format a nice message to print out and return to the user.
   */
  log_msg =
      fmt::format("🎣 Retrieved Index. [name={} d={}, metric_type={} ntotal={}]",
                  index_name, index->d, index->metric_type, index->ntotal);
  spdlog::info(log_msg);

  return grpc::Status(grpc::StatusCode::OK, log_msg);
}

grpc::Status
NNextServiceImpl::ListIndices(grpc::ServerContext *p_context,
                              const nnext::ListIndicesRequest *p_request,
                              nnext::ListIndicesResponse *p_response) {

  std::string log_msg;
  auto _indices_pb = p__index_list_pb->mutable_indices();

  /*
   * Copy over the index protobuf for return.
   * TODO (Peter) Implement result pagination.
   */
  for (auto iter = _indices_pb->begin(); iter < _indices_pb->end(); iter++) {
    nnext::Index *new_index = p_response->add_indices();
    new_index->set_name(iter->name());
    new_index->set_dims(iter->dims());
  }

  p_response->set_total(index_map.size());

  /*
   * Format a nice message and return to the user.
   */
  log_msg = fmt::format("Found {} indices", _indices_pb->size());
  spdlog::info(log_msg);

  return grpc::Status(grpc::StatusCode::OK, log_msg);
}

grpc::Status NNextServiceImpl::CreateIndex(grpc::ServerContext *p_context,
                                           const nnext::Index *p_request,
                                           nnext::Index *p_response) {

  std::string index_name = p_request->name();
  std::string log_msg;

  /*
   * First check that the index is *NOT* contained in the map.
   */
  if (index_map.contains(index_name)) {
    log_msg = fmt::format("NNext error ⚠️: Index already exists [name={}]",
                          index_name);
    spdlog::error(log_msg);
    return grpc::Status(grpc::StatusCode::ALREADY_EXISTS, log_msg);
  }

  rocksdb::Status db_status;
  int dims = p_request->dims();

  /*
   * Create the FAISS index and add to the map of indices. Indices are keyed by
   * their name.
   */
  faiss::IndexFlat quantizer(dims);
  const size_t nlist = 4; // Number of cluster centroids.
  int m_pq = std::min(128, dims);
  int M = 16; // Number of neighbors used in the graph. A larger M is more
              // accurate but uses more memory
  std::vector<float> data_vec;

  /*
   * Create the approximated HNSW index and the storage (quantizer)
   */
  std::shared_ptr ptr__quantizer = std::make_shared<faiss::IndexFlat>(dims);
  std::shared_ptr curr_index = std::make_shared<faiss::IndexHNSW2Level>(
      ptr__quantizer.get(), nlist, m_pq, M);

  /*
   * Add the ANN index and quantizer into the map.
   */
  index_map.insert(std::make_pair(index_name, curr_index));
  storage_map.insert(std::make_pair(index_name, ptr__quantizer));

  /*
   * Create the ProtoBuf index representation for later serialization.
   */
  nnext::Index *index_pb = p__index_list_pb->add_indices();
  index_pb->CopyFrom(*p_request);

  /*
   * Parse and validate the schema. Return an error if invalid.
   */
  try {
    auto parsed_schema = parse_index_schema(p_request->schema());
    index_pb->mutable_schema()->CopyFrom(parsed_schema);
  } catch (const std::invalid_argument &ia) {
    log_msg = fmt::format("Invalid argument: {}", ia.what());
    spdlog::error(log_msg);
    return grpc::Status(grpc::StatusCode::INTERNAL, log_msg);
  }

  /*
   * Serialize the IndexList Proto to string.
   */
  std::string index_list_pb_str;
  p__index_list_pb->SerializeToString(&index_list_pb_str);

  /*
   * Persist the PB to memory using RocksDB.
   */
  db_status =
      _rocksdb->Put(rocksdb::WriteOptions(), "indices", index_list_pb_str);
  if (!db_status.ok()) {
    log_msg = fmt::format("RocksDB error {}", db_status.ToString());
    spdlog::error("RocksDB error {}", db_status.ToString());
    return grpc::Status(grpc::StatusCode::INTERNAL, log_msg);
  }

  /*
   * Set the return Proto values for the newly created index.
   */
  p_response->CopyFrom(*index_pb);

  /*
   * Format a nice message to print out and return to the user.
   */
  log_msg =
      fmt::format("✨ Created Index. \n[index={}]", index_pb->DebugString());
  spdlog::info(log_msg);

  return grpc::Status(grpc::StatusCode::OK, log_msg);
}

grpc::Status NNextServiceImpl::DropIndex(grpc::ServerContext *p_context,
                                         const nnext::Index *p_request,
                                         nnext::Index *p_response) {
  rocksdb::Status db_status;
  bool found_index = false;
  std::string log_msg;
  std::string index_name = p_request->name();
  auto _indices_pb = p__index_list_pb->mutable_indices();

  /*
   * First check that the index is actually contained in the map.
   */
  if (!index_map.contains(index_name)) {
    log_msg = fmt::format("⚠️  Could not find index [name={}]", index_name);
    spdlog::error(log_msg);
    return grpc::Status(grpc::StatusCode::NOT_FOUND, log_msg);
  }

  /*
   * Find the index to be deleted from the protobuf and remove it.
   */
  for (int i = 0; i < _indices_pb->size(); i++) {
    nnext::Index _index = _indices_pb->at(i);

    if (_index.name() == index_name) {
      // Protobuf does not allow arbitrarily deleting elements and subsequent
      // compacting. Swap the element to be removed with the last one then pop
      // it from the end of the list.
      _indices_pb->SwapElements(i, _indices_pb->size() - 1);
      _indices_pb->RemoveLast();
      spdlog::debug(
          "Removed index from Protobuf list. [name={}, idx={}, size={}]",
          index_name, i, _indices_pb->size());
      found_index = true;
      break;
    }
  }

  /*
   * Check that the index was actually found in the protobuf. Return early with
   * a NOT_FOUND status if not.
   */
  if (!found_index) {
    log_msg = fmt::format("⚠️  Could not find index [name={}]", index_name);
    spdlog::error(log_msg);
    return grpc::Status(grpc::StatusCode::NOT_FOUND, log_msg);
  }

  /*
   * Persist the index list protobuf to storage using RocksDB.
   */
  std::string index_list_pb_str;
  p__index_list_pb->SerializeToString(&index_list_pb_str);

  db_status =
      _rocksdb->Put(rocksdb::WriteOptions(), "indices", index_list_pb_str);
  if (!db_status.ok())
    spdlog::error("RocksDB error {}", db_status.ToString());

  /*
   * Populate the return object.
   */
  auto index = index_map[index_name];
  p_response->set_name(index_name);
  p_response->set_dims(index->d);
  p_response->set_ntotal(index->ntotal);
  p_response->set_is_trained(index->is_trained);

  /*
   * Remove the index from the index map.
   */
  index_map.erase(index_name);

  /*
   * Format a nice error message to return to the user.
   */
  log_msg = fmt::format("🗑 Dropped index. [name={}]", index_name);
  spdlog::info(log_msg);

  return grpc::Status(grpc::StatusCode::OK, log_msg);
}

/*
 * Vector Methods
 */
grpc::Status
NNextServiceImpl::VectorAdd(grpc::ServerContext *p_context,
                            const nnext::VectorAddRequest *p_request,
                            nnext::VectorAddResponse *p_response) {

  std::string index_name = p_request->index_name();
  std::string log_msg;

  /*
   * Check that the index exists and exit early if not.
   */
  if (index_map.count(index_name) < 1) {
    log_msg = fmt::format("⚠️  Could not find index [name={}]", index_name);
    spdlog::error(log_msg);
    return grpc::Status(grpc::StatusCode::NOT_FOUND, log_msg);
  }

  /*
   * TODO:
   * 1. Write vectors to disk.
   * 2. Load vectors from disk on restart.
   * 3. Bifurcate the vector storage engine. For n < 10,000 and d < 1024 use
   * IndexFlat.
   */

  auto curr_index = index_map[index_name];
  auto curr_quantizer = storage_map[index_name];
  const auto req_data = p_request->data();
  const int n = req_data.size();
  const int d = curr_index->d;

  /*
   * Ensure that the request contains data to add. Exit early it not.
   */
  if (n == 0) {
    log_msg = fmt::format("⚠️  No data to add.");
    spdlog::error(log_msg);
    return grpc::Status(grpc::StatusCode::NOT_FOUND, log_msg);
  }

  std::vector<float> data_vec;
  rocksdb::Status db_status;
  // pk_type _pk_type;
  // string _pk_name = "xxx";

  /*
   * Create and reserve the Vector List PB for later serialization in
   * column-order to disk.
   */
  if (pb__vector_list_map.count(index_name) < 1) {
    pb__vector_list_map[index_name] = std::make_shared<nnext::VectorList>();
  }
  auto pb__vector_list = pb__vector_list_map[index_name];

  /*
   * Extract the vector data array
   */
  for (auto pb_data : req_data) {
    //   auto _datum = Datum(pb_data, _pk_type, _pk_name);
    auto vector = pb_data.rptd__vector();
    data_vec.insert(data_vec.end(), vector.begin(), vector.end());

    //    std::string rocks_key = fmt::format("{}::{}", index_name,
    //    _datum.pk());
    //
    //    data_map[_datum.pk] = _datum;
    //
    //    std::cout << _datum.pk << std::endl;
    //
    //    db_status = _rocksdb->Put(rocksdb::WriteOptions(), rocks_key,
    //    datum.to_string());

    if (!db_status.ok()) {
      log_msg = fmt::format("RocksDB error {}", db_status.ToString());
      spdlog::error("RocksDB error {}", db_status.ToString());
      return grpc::Status(grpc::StatusCode::INTERNAL, log_msg);
    }

    /*
     * Construct the elements of the serializable Vector List.
     */
    nnext::Vector *pb__vector = pb__vector_list->add_rptd__vector();
    pb__vector->mutable_rptd__element()->Add(vector.begin(), vector.end());
  }

  /*
   * Serialize the IndexList Proto to string.
   */
  std::string str__vector_list;
  pb__vector_list->SerializeToString(&str__vector_list);

  /*
   * Persist the Vector List PB to memory using RocksDB.
   */
  std::string vector_list_key = fmt::format("index__{}__vectors]", index_name);

  spdlog::debug(
      "Serializing vectors and persisting to disk [key={} size<bytes>={}]",
      vector_list_key, str__vector_list.size());
  db_status =
      _rocksdb->Put(rocksdb::WriteOptions(), vector_list_key, str__vector_list);

  if (!db_status.ok()) {
    log_msg = fmt::format("RocksDB error {}", db_status.ToString());
    spdlog::error("RocksDB error {}", db_status.ToString());
    return grpc::Status(grpc::StatusCode::INTERNAL, log_msg);
  }

  log_msg =
      fmt::format("Adding data to index [name={} ntotal={} is_trained={}"
                  " n={} d={}]",
                  index_name, curr_index->ntotal, curr_index->is_trained, n, d);
  spdlog::info(log_msg);

  /*
   * Train the index (if untrained). Useful for the first time that vectors are
   * added to the index.
   */
  const int n_total = n + curr_index->ntotal;
  log_msg = fmt::format("n_total={}", n_total);
  spdlog::info(log_msg);

  if (n_total > 5000) {
    if (!curr_index->is_trained) {
      int n_train = std::min(n, 300);
      n_train = 0;

      spdlog::debug("Training index [n_train={}, n_total={}]", n_train,
                    n_total);
      curr_index->train(n_train, &data_vec[0]);
    }

    /*
     * Add the elements to the index. Note we can directly access the underlying
     * float array pointer from the std::vector since vector elements are
     * guaranteed to be contiguous.
     */

    spdlog::debug("Adding to index IndexHNSW [data_vec.size()={}]",
                  data_vec.size());
    curr_index->add(n, &data_vec[0]);
  } else {
    spdlog::debug("Adding to index IndexFLAT [data_vec.size()={}]",
                  data_vec.size());
    curr_quantizer->add(n, &data_vec[0]);
  }

  /*
   * Format a nice response message to return to the user.
   */
  log_msg = fmt::format("Added data to index [name={} curr_index->ntotal={} "
                        "curr_index->ntotal={} is_trained={}]",
                        index_name, curr_index->ntotal, curr_index->ntotal,
                        curr_index->is_trained);

  spdlog::info(log_msg);

  return grpc::Status(grpc::StatusCode::OK, log_msg);
}

grpc::Status
NNextServiceImpl::VectorGet(grpc::ServerContext *p_context,
                            const nnext::VectorGetRequest *p_request,
                            nnext::VectorGetResponse *p_response) {

  std::string index_name = p_request->index_name();
  std::string log_msg;

  /*
   * Check that the index exists and exit early if not.
   */
  if (index_map.count(index_name) < 1) {
    log_msg = fmt::format("⚠️  Could not find index [name={}]", index_name);
    spdlog::error(log_msg);
    return grpc::Status(grpc::StatusCode::NOT_FOUND, log_msg);
  }

  // TODO: Implement VectorGet

  //
  //  auto index = index_map->at(index_name);
  //  int n = data.size();
  //  const int dims = 768;
  //  auto x = p_request->data();
  //  float x_data[n * dims];
  //
  //
  //  float _data[dims * n];
  //
  //  for (int i = 0; i < n; i++) {
  //    const nnext::Vector q_vector = p_request->q_vectors(i);
  //    for (int j = 0; j < dims; j++) {
  //      query_data[dims * i + j] = q_vector.data(j);
  //    }
  //  }
  //
  //
  //  for (auto iter = data.begin(); iter < data.end(); iter++) {
  //    auto vector = iter->vector();
  //    index.add(vector.size(), vector.mutable_data());
  //  }
  //
  //  index.add(dims, _data);

  //  spdlog::debug("🔆🔆 {} {} {}", index.ntotal, index.is_trained,
  //  index_map->size());

  /*
   * Format a nice error message to return to the user.
   */
  //  log_msg = fmt::format("Added {} vectors to index. [name={}]", n,
  //  index_name); spdlog::info(log_msg);

  return grpc::Status(grpc::StatusCode::OK, log_msg);
}

grpc::Status
NNextServiceImpl::VectorSearch(grpc::ServerContext *p_context,
                               const nnext::VectorSearchRequest *p_request,
                               nnext::VectorSearchResponse *p_response) {

  std::string index_name = p_request->index_name();
  std::string log_msg;

  /*
   * Check that the index exists and exit early it not.
   */
  if (index_map.count(index_name) < 1) {
    log_msg = fmt::format("⚠️  Could not find index [name={}]", index_name);
    spdlog::error(log_msg);
    return grpc::Status(grpc::StatusCode::NOT_FOUND, log_msg);
  }

  auto curr_index = index_map[index_name];
  auto curr_quantizer = storage_map[index_name];
  const auto query_vectors = p_request->rptd_query_vector();
  const int n = query_vectors.size();
  const faiss::Index::idx_t k = p_request->k();
  int d = curr_index->d;
  int ntotal = curr_quantizer->ntotal;
  std::vector<float> data_vec;
  std::vector<faiss::Index::idx_t> labels(k * n);
  std::vector<float> distances(k * n);
  std::vector<float> recons(k * n * d);
  rocksdb::Status db_status;

  /*
   * Extract the query vector data array
   */
  for (auto pb_data : query_vectors) {
    auto vector = pb_data.rptd__element();

    /*
     * Check that the dimensions match. Return error if not.
     */
    if (d != vector.size()) {
      log_msg =
          fmt::format("❗️ Query vector size does not match index dims. "
                      "[index.dims={} query.dims={}]",
                      d, vector.size());
      spdlog::error(log_msg);
      return grpc::Status(grpc::StatusCode::INVALID_ARGUMENT, log_msg);
    }

    data_vec.insert(data_vec.end(), vector.begin(), vector.end());
  }

  /*
   * Assign the labels of the k vectors closest to the query x.
   */
  log_msg =
      fmt::format("Querying nearest neighbor vectors. [k={} n={} "
                  "omit_vector={} omit_metadata={}]",
                  k, n, p_request->omit_vector(), p_request->omit_metadata());
  spdlog::info(log_msg);

  log_msg = fmt::format("[curr_quantizer->ntotal={} curr_index->ntotal={} ",
                        curr_quantizer->ntotal, curr_index->ntotal);
  spdlog::info(log_msg);

  if (ntotal < INDEX_SIZE_THRESHOLD) {

    if (!p_request->omit_vector()) {
      curr_quantizer->search_and_reconstruct(n, &data_vec[0], k, &distances[0], &labels[0], &recons[0]);

      log_msg = fmt::format("Reconstructing vectors.");
      spdlog::info(log_msg);

      // Set nearest neighbor indices and vectors on response datum
      for (size_t i = 0; i < (unsigned int)k * n; i++) {
        auto datum = p_response->add_rptd__datum();

        std::string _id = fmt::format("{}", labels[i]);
        datum->set_id(_id);
        // TODO: Look into fastest copy operation to use here.
        for (int j = 0; j < d; j++) {
          datum->add_rptd__vector((float)recons[i * d + j]);
        }
      }
    }

    // TODO: Conditional logic here needs to change to reflect the 2^2 possible combinations of
    // omit_metadata and omit_vector cases.
    // Ignoring this for now since the handler is not implemented anyway.
    if (!p_request->omit_metadata()) {
      log_msg = fmt::format("[NOT IMPLEMENTED] Retrieving metadata for nearest neighbor vectors.");
      spdlog::info(log_msg);
      // TODO: Now actually retrieve metadata.
    }

    // Set nearest neighbor indices on response datum
    else {
      curr_quantizer->search(n, &data_vec[0], k, &distances[0], &labels[0]);

      for (int l : labels) {
        auto datum = p_response->add_rptd__datum();

        std::string _id = fmt::format("{}", l);
        datum->set_id(_id);
      }
    }
  }

  // TODO: Implement construction of response for ntotal >= INDEX_SIZE_THRESHOLD case
  // Not sure yet why this case was separated out above.

  p_response->set_ntotal(n);

  //  try {
  //    curr_index->assign(n, &data_vec[0], &labels[0], k);
  //  } catch (faiss::FaissException &ex) {
  //    spdlog::critical("FaissException: {}", ex.what());
  //  } catch (std::exception &ex) {
  //    spdlog::critical("std::exception: {}", ex.what());
  //  } catch (...) {
  //    std::exception_ptr p = std::current_exception();
  //    std::clog << (p ? p.__cxa_exception_type()->name() : "null") <<
  //    std::endl;
  //  }

  /*
   * Format a nice response message to return to the user.
   */
  log_msg =
      fmt::format("Retrieved nearest neighbor vectors. [k={} n={} "
                  "omit_vector={} omit_metadata={}]",
                  k, n, p_request->omit_vector(), p_request->omit_metadata());

  spdlog::info(log_msg);

  return grpc::Status(grpc::StatusCode::OK, log_msg);
}